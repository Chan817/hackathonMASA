{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. train and test split\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       Agency    Agency Type Distribution Channel  \\\n",
       "0        CBH  Travel Agency              Offline   \n",
       "1        CBH  Travel Agency              Offline   \n",
       "2        CWT  Travel Agency               Online   \n",
       "3        CWT  Travel Agency               Online   \n",
       "4        CWT  Travel Agency               Online   \n",
       "...      ...            ...                  ...   \n",
       "63321    JZI       Airlines               Online   \n",
       "63322    JZI       Airlines               Online   \n",
       "63323    JZI       Airlines               Online   \n",
       "63324    JZI       Airlines               Online   \n",
       "63325    JZI       Airlines               Online   \n",
       "\n",
       "                          Product Name Claim  Duration Destination  Net Sales  \\\n",
       "0                   Comprehensive Plan    No       186    MALAYSIA      -29.0   \n",
       "1                   Comprehensive Plan    No       186    MALAYSIA      -29.0   \n",
       "2      Rental Vehicle Excess Insurance    No        65   AUSTRALIA      -49.5   \n",
       "3      Rental Vehicle Excess Insurance    No        60   AUSTRALIA      -39.6   \n",
       "4      Rental Vehicle Excess Insurance    No        79       ITALY      -19.8   \n",
       "...                                ...   ...       ...         ...        ...   \n",
       "63321                       Basic Plan    No       111       JAPAN       35.0   \n",
       "63322                       Basic Plan    No        58       CHINA       40.0   \n",
       "63323                       Basic Plan    No         2    MALAYSIA       18.0   \n",
       "63324                       Basic Plan    No         3    VIET NAM       18.0   \n",
       "63325                       Basic Plan    No        22   HONG KONG       26.0   \n",
       "\n",
       "       Commision (in value) Gender  Age  \n",
       "0                      9.57      F   81  \n",
       "1                      9.57      F   71  \n",
       "2                     29.70    NaN   32  \n",
       "3                     23.76    NaN   32  \n",
       "4                     11.88    NaN   41  \n",
       "...                     ...    ...  ...  \n",
       "63321                 12.25      M   31  \n",
       "63322                 14.00      F   40  \n",
       "63323                  6.30      M   57  \n",
       "63324                  6.30      M   63  \n",
       "63325                  9.10      F   35  \n",
       "\n",
       "[63326 rows x 11 columns]>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x20f3bc2fc70>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df['Net Sales'], df['Commision (in value)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Net Sales']]\n",
    "y = df['Commision (in value)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Net Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-49.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-39.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63321</th>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63322</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63323</th>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63324</th>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63325</th>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63326 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Net Sales\n",
       "0          -29.0\n",
       "1          -29.0\n",
       "2          -49.5\n",
       "3          -39.6\n",
       "4          -19.8\n",
       "...          ...\n",
       "63321       35.0\n",
       "63322       40.0\n",
       "63323       18.0\n",
       "63324       18.0\n",
       "63325       26.0\n",
       "\n",
       "[63326 rows x 1 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         9.57\n",
       "1         9.57\n",
       "2        29.70\n",
       "3        23.76\n",
       "4        11.88\n",
       "         ...  \n",
       "63321    12.25\n",
       "63322    14.00\n",
       "63323     6.30\n",
       "63324     6.30\n",
       "63325     9.10\n",
       "Name: Commision (in value), Length: 63326, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,  y, test_size=0.2, \n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12666"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "clf = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17.34655837,  6.2428087 , 18.13968335, ..., -0.8953161 ,\n",
       "        8.35780863,  8.35780863])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8997      0.00\n",
       "48902     0.00\n",
       "55873    28.80\n",
       "9964     17.82\n",
       "21093     0.00\n",
       "         ...  \n",
       "45141    54.00\n",
       "32814     0.00\n",
       "33250    11.88\n",
       "59135    12.25\n",
       "44408    12.25\n",
       "Name: Commision (in value), Length: 12666, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42764738846803685"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Model Development\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVR_model = SVR()\n",
    "SVR_model.fit(X_train, y_train)\n",
    "SVR_prediction = SVR_model.predict(X_test)\n",
    "print(accuracy_score(SVR_prediction, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\Documents\\masa hackathon\\New folder\\sprint4oridata.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/masa%20hackathon/New%20folder/sprint4oridata.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m KNN_model \u001b[39m=\u001b[39m KNeighborsClassifier(n_neighbors\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/masa%20hackathon/New%20folder/sprint4oridata.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m KNN_model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/masa%20hackathon/New%20folder/sprint4oridata.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m KNN_prediction \u001b[39m=\u001b[39m KNN_model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/masa%20hackathon/New%20folder/sprint4oridata.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(accuracy_score(SVR_prediction, y_test))\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:200\u001b[0m, in \u001b[0;36mKNeighborsClassifier.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[39m\"\"\"Fit the k-nearest neighbors classifier from the training dataset.\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \n\u001b[0;32m    183\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[39m    The fitted k-nearest neighbors classifier.\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39m=\u001b[39m _check_weights(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights)\n\u001b[1;32m--> 200\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_base.py:429\u001b[0m, in \u001b[0;36mNeighborsBase._fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    427\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutputs_2d_ \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 429\u001b[0m check_classification_targets(y)\n\u001b[0;32m    430\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m []\n\u001b[0;32m    431\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(y\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\multiclass.py:200\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    192\u001b[0m y_type \u001b[39m=\u001b[39m type_of_target(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\n\u001b[0;32m    194\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    195\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmultilabel-sequences\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    199\u001b[0m ]:\n\u001b[1;32m--> 200\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnknown label type: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "KNN_model = KNeighborsClassifier(n_neighbors=5)\n",
    "KNN_model.fit(X_train, y_train)\n",
    "KNN_prediction = KNN_model.predict(X_test)\n",
    "print(accuracy_score(SVR_prediction, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (array([0.0000e+00, 2.0000e-02, 4.0000e-02, 5.0000e-02, 9.0000e-02,\n       1.3000e-01, 1.4000e-01, 1.5000e-01, 1.6000e-01, 1.8000e-01,\n       2.0000e-01, 2.1000e-01, 2.2000e-01, 2.3000e-01, 2.4000e-01,\n       2.5000e-01, 2.6000e-01, 2.7000e-01, 2.8000e-01, 2.9000e-01,\n       3.1000e-01, 3.2000e-01, 3.4000e-01, 3.6000e-01, 3.7000e-01,\n       3.8000e-01, 4.1000e-01, 4.3000e-01, 4.4000e-01, 4.5000e-01,\n       4.7000e-01, 4.9000e-01, 5.0000e-01, 5.1000e-01, 5.4000e-01,\n       5.6000e-01, 5.8000e-01, 5.9000e-01, 6.3000e-01, 6.5000e-01,\n       6.6000e-01, 6.7000e-01, 6.8000e-01, 6.9000e-01, 7.0000e-01,\n       7.1000e-01, 7.4000e-01, 7.5000e-01, 7.7000e-01, 7.9000e-01,\n       8.0000e-01, 8.1000e-01, 8.3000e-01, 8.4000e-01, 8.5000e-01,\n       8.6000e-01, 8.7000e-01, 8.8000e-01, 9.0000e-01, 9.3000e-01,\n       9.4000e-01, 9.5000e-01, 9.6000e-01, 9.7000e-01, 9.8000e-01,\n       9.9000e-01, 1.0000e+00, 1.0100e+00, 1.0200e+00, 1.0300e+00,\n       1.0500e+00, 1.0600e+00, 1.0700e+00, 1.0800e+00, 1.0900e+00,\n       1.1000e+00, 1.1200e+00, 1.1300e+00, 1.1600e+00, 1.1700e+00,\n       1.1800e+00, 1.1900e+00, 1.2000e+00, 1.2100e+00, 1.2200e+00,\n       1.2300e+00, 1.2400e+00, 1.2500e+00, 1.2600e+00, 1.2700e+00,\n       1.2900e+00, 1.3000e+00, 1.3100e+00, 1.3200e+00, 1.3300e+00,\n       1.3400e+00, 1.3700e+00, 1.3900e+00, 1.4200e+00, 1.4300e+00,\n       1.4700e+00, 1.4800e+00, 1.5000e+00, 1.5100e+00, 1.5300e+00,\n       1.5400e+00, 1.5500e+00, 1.5700e+00, 1.5900e+00, 1.6000e+00,\n       1.6100e+00, 1.6300e+00, 1.6500e+00, 1.6600e+00, 1.6800e+00,\n       1.6900e+00, 1.7000e+00, 1.7100e+00, 1.7200e+00, 1.7300e+00,\n       1.7400e+00, 1.7500e+00, 1.7600e+00, 1.8000e+00, 1.8200e+00,\n       1.8400e+00, 1.8600e+00, 1.8800e+00, 1.9000e+00, 1.9400e+00,\n       1.9500e+00, 1.9600e+00, 1.9900e+00, 2.0000e+00, 2.0100e+00,\n       2.0200e+00, 2.0300e+00, 2.0600e+00, 2.1300e+00, 2.1500e+00,\n       2.1600e+00, 2.1900e+00, 2.2000e+00, 2.2100e+00, 2.2200e+00,\n       2.2300e+00, 2.2400e+00, 2.2500e+00, 2.3400e+00, 2.3500e+00,\n       2.3600e+00, 2.3800e+00, 2.4100e+00, 2.4200e+00, 2.4600e+00,\n       2.4700e+00, 2.5100e+00, 2.5200e+00, 2.5600e+00, 2.5700e+00,\n       2.6000e+00, 2.6200e+00, 2.6400e+00, 2.7300e+00, 2.7400e+00,\n       2.7500e+00, 2.7600e+00, 2.8000e+00, 2.8100e+00, 2.8300e+00,\n       2.8700e+00, 2.8800e+00, 2.8900e+00, 2.9100e+00, 2.9200e+00,\n       2.9500e+00, 2.9600e+00, 3.0100e+00, 3.0200e+00, 3.0500e+00,\n       3.0800e+00, 3.0900e+00, 3.1000e+00, 3.1400e+00, 3.1500e+00,\n       3.2100e+00, 3.2300e+00, 3.2500e+00, 3.2800e+00, 3.2900e+00,\n       3.3300e+00, 3.3500e+00, 3.3800e+00, 3.3900e+00, 3.4100e+00,\n       3.4500e+00, 3.4600e+00, 3.5200e+00, 3.5300e+00, 3.5500e+00,\n       3.6000e+00, 3.6100e+00, 3.6200e+00, 3.6600e+00, 3.6800e+00,\n       3.7300e+00, 3.7400e+00, 3.7500e+00, 3.7600e+00, 3.7700e+00,\n       3.8000e+00, 3.8500e+00, 3.8700e+00, 3.9200e+00, 3.9400e+00,\n       3.9500e+00, 4.0000e+00, 4.0200e+00, 4.0300e+00, 4.0400e+00,\n       4.0500e+00, 4.0600e+00, 4.1300e+00, 4.1800e+00, 4.2000e+00,\n       4.2100e+00, 4.2500e+00, 4.2800e+00, 4.3000e+00, 4.3100e+00,\n       4.3800e+00, 4.3900e+00, 4.4000e+00, 4.4300e+00, 4.5000e+00,\n       4.5400e+00, 4.5500e+00, 4.5900e+00, 4.6000e+00, 4.6300e+00,\n       4.6500e+00, 4.6700e+00, 4.7200e+00, 4.7400e+00, 4.8000e+00,\n       4.8800e+00, 4.9100e+00, 4.9200e+00, 4.9300e+00, 4.9400e+00,\n       4.9900e+00, 5.0000e+00, 5.0400e+00, 5.0600e+00, 5.1200e+00,\n       5.1300e+00, 5.1400e+00, 5.2000e+00, 5.2500e+00, 5.2600e+00,\n       5.3400e+00, 5.3800e+00, 5.4800e+00, 5.5000e+00, 5.5300e+00,\n       5.5500e+00, 5.6000e+00, 5.6300e+00, 5.7200e+00, 5.7300e+00,\n       5.7500e+00, 5.7900e+00, 5.8500e+00, 5.8800e+00, 5.9100e+00,\n       5.9300e+00, 5.9400e+00, 5.9500e+00, 5.9800e+00, 6.0000e+00,\n       6.0100e+00, 6.1300e+00, 6.1700e+00, 6.2000e+00, 6.2400e+00,\n       6.2500e+00, 6.2800e+00, 6.3000e+00, 6.3200e+00, 6.3800e+00,\n       6.3900e+00, 6.4200e+00, 6.4700e+00, 6.5000e+00, 6.5100e+00,\n       6.5700e+00, 6.6300e+00, 6.6500e+00, 6.6600e+00, 6.6700e+00,\n       6.7300e+00, 6.7500e+00, 6.8200e+00, 6.8400e+00, 6.8500e+00,\n       6.8800e+00, 6.9400e+00, 6.9600e+00, 6.9900e+00, 7.0000e+00,\n       7.0200e+00, 7.0500e+00, 7.1300e+00, 7.1600e+00, 7.2100e+00,\n       7.2500e+00, 7.3500e+00, 7.3600e+00, 7.3800e+00, 7.4700e+00,\n       7.5000e+00, 7.6400e+00, 7.6900e+00, 7.7000e+00, 7.7600e+00,\n       7.8000e+00, 7.8700e+00, 7.8900e+00, 7.9100e+00, 7.9500e+00,\n       7.9600e+00, 8.0000e+00, 8.0500e+00, 8.0600e+00, 8.1000e+00,\n       8.1300e+00, 8.2100e+00, 8.2200e+00, 8.2500e+00, 8.3600e+00,\n       8.3800e+00, 8.4000e+00, 8.5000e+00, 8.5700e+00, 8.6300e+00,\n       8.6800e+00, 8.7000e+00, 8.7100e+00, 8.7500e+00, 8.7600e+00,\n       8.7700e+00, 8.7800e+00, 8.8100e+00, 8.8500e+00, 8.8800e+00,\n       8.9000e+00, 8.9600e+00, 8.9900e+00, 9.0000e+00, 9.1000e+00,\n       9.1300e+00, 9.1900e+00, 9.2000e+00, 9.2500e+00, 9.2600e+00,\n       9.3000e+00, 9.3800e+00, 9.4500e+00, 9.5700e+00, 9.5900e+00,\n       9.7500e+00, 9.9700e+00, 1.0000e+01, 1.0050e+01, 1.0130e+01,\n       1.0150e+01, 1.0160e+01, 1.0180e+01, 1.0220e+01, 1.0250e+01,\n       1.0320e+01, 1.0330e+01, 1.0380e+01, 1.0500e+01, 1.0630e+01,\n       1.0640e+01, 1.0660e+01, 1.0690e+01, 1.0830e+01, 1.0850e+01,\n       1.0890e+01, 1.1020e+01, 1.1060e+01, 1.1100e+01, 1.1130e+01,\n       1.1200e+01, 1.1210e+01, 1.1250e+01, 1.1340e+01, 1.1380e+01,\n       1.1500e+01, 1.1540e+01, 1.1550e+01, 1.1580e+01, 1.1630e+01,\n       1.1700e+01, 1.1720e+01, 1.1750e+01, 1.1780e+01, 1.1830e+01,\n       1.1860e+01, 1.1880e+01, 1.1900e+01, 1.2000e+01, 1.2070e+01,\n       1.2090e+01, 1.2130e+01, 1.2140e+01, 1.2170e+01, 1.2250e+01,\n       1.2300e+01, 1.2380e+01, 1.2390e+01, 1.2400e+01, 1.2450e+01,\n       1.2500e+01, 1.2540e+01, 1.2560e+01, 1.2600e+01, 1.2630e+01,\n       1.2750e+01, 1.2940e+01, 1.2950e+01, 1.2960e+01, 1.3000e+01,\n       1.3020e+01, 1.3130e+01, 1.3160e+01, 1.3200e+01, 1.3210e+01,\n       1.3250e+01, 1.3310e+01, 1.3380e+01, 1.3420e+01, 1.3490e+01,\n       1.3500e+01, 1.3570e+01, 1.3630e+01, 1.3650e+01, 1.3750e+01,\n       1.3880e+01, 1.3920e+01, 1.3950e+01, 1.4000e+01, 1.4100e+01,\n       1.4130e+01, 1.4180e+01, 1.4250e+01, 1.4380e+01, 1.4440e+01,\n       1.4460e+01, 1.4500e+01, 1.4530e+01, 1.4550e+01, 1.4630e+01,\n       1.4700e+01, 1.4750e+01, 1.4790e+01, 1.4850e+01, 1.4880e+01,\n       1.5000e+01, 1.5190e+01, 1.5280e+01, 1.5380e+01, 1.5400e+01,\n       1.5440e+01, 1.5500e+01, 1.5560e+01, 1.5570e+01, 1.5600e+01,\n       1.5750e+01, 1.5880e+01, 1.5900e+01, 1.5930e+01, 1.5960e+01,\n       1.6000e+01, 1.6050e+01, 1.6090e+01, 1.6160e+01, 1.6250e+01,\n       1.6270e+01, 1.6350e+01, 1.6410e+01, 1.6450e+01, 1.6500e+01,\n       1.6570e+01, 1.6610e+01, 1.6700e+01, 1.6750e+01, 1.6800e+01,\n       1.6900e+01, 1.6950e+01, 1.7130e+01, 1.7150e+01, 1.7230e+01,\n       1.7250e+01, 1.7290e+01, 1.7380e+01, 1.7390e+01, 1.7500e+01,\n       1.7540e+01, 1.7550e+01, 1.7630e+01, 1.7710e+01, 1.7750e+01,\n       1.7820e+01, 1.7850e+01, 1.8000e+01, 1.8040e+01, 1.8130e+01,\n       1.8200e+01, 1.8240e+01, 1.8250e+01, 1.8380e+01, 1.8560e+01,\n       1.8600e+01, 1.8620e+01, 1.8630e+01, 1.8730e+01, 1.8800e+01,\n       1.8850e+01, 1.8900e+01, 1.9000e+01, 1.9010e+01, 1.9050e+01,\n       1.9070e+01, 1.9130e+01, 1.9140e+01, 1.9250e+01, 1.9340e+01,\n       1.9350e+01, 1.9500e+01, 1.9600e+01, 1.9630e+01, 1.9650e+01,\n       1.9950e+01, 1.9990e+01, 2.0000e+01, 2.0030e+01, 2.0060e+01,\n       2.0130e+01, 2.0150e+01, 2.0250e+01, 2.0280e+01, 2.0300e+01,\n       2.0380e+01, 2.0440e+01, 2.0480e+01, 2.0640e+01, 2.0650e+01,\n       2.0690e+01, 2.0700e+01, 2.0750e+01, 2.0800e+01, 2.0820e+01,\n       2.0850e+01, 2.0880e+01, 2.0960e+01, 2.0980e+01, 2.1000e+01,\n       2.1130e+01, 2.1350e+01, 2.1450e+01, 2.1500e+01, 2.1600e+01,\n       2.1630e+01, 2.1700e+01, 2.1750e+01, 2.1850e+01, 2.2000e+01,\n       2.2040e+01, 2.2050e+01, 2.2090e+01, 2.2100e+01, 2.2130e+01,\n       2.2230e+01, 2.2250e+01, 2.2310e+01, 2.2360e+01, 2.2400e+01,\n       2.2470e+01, 2.2730e+01, 2.2750e+01, 2.2910e+01, 2.2960e+01,\n       2.3060e+01, 2.3180e+01, 2.3250e+01, 2.3400e+01, 2.3450e+01,\n       2.3500e+01, 2.3600e+01, 2.3630e+01, 2.3730e+01, 2.3750e+01,\n       2.3760e+01, 2.3810e+01, 2.3970e+01, 2.4000e+01, 2.4150e+01,\n       2.4170e+01, 2.4380e+01, 2.4400e+01, 2.4440e+01, 2.4450e+01,\n       2.4750e+01, 2.4800e+01, 2.4850e+01, 2.4860e+01, 2.5020e+01,\n       2.5080e+01, 2.5130e+01, 2.5200e+01, 2.5250e+01, 2.5480e+01,\n       2.5500e+01, 2.5510e+01, 2.5520e+01, 2.5550e+01, 2.5620e+01,\n       2.5680e+01, 2.5840e+01, 2.5880e+01, 2.6000e+01, 2.6400e+01,\n       2.6500e+01, 2.6550e+01, 2.6590e+01, 2.6600e+01, 2.6630e+01,\n       2.6750e+01, 2.6980e+01, 2.7000e+01, 2.7190e+01, 2.7250e+01,\n       2.7300e+01, 2.7360e+01, 2.7460e+01, 2.7500e+01, 2.7560e+01,\n       2.7750e+01, 2.8000e+01, 2.8130e+01, 2.8250e+01, 2.8280e+01,\n       2.8350e+01, 2.8500e+01, 2.8600e+01, 2.8690e+01, 2.8760e+01,\n       2.8800e+01, 2.8850e+01, 2.8930e+01, 2.8950e+01, 2.9050e+01,\n       2.9130e+01, 2.9380e+01, 2.9440e+01, 2.9500e+01, 2.9570e+01,\n       2.9700e+01, 2.9750e+01, 3.0000e+01, 3.0160e+01, 3.0250e+01,\n       3.0450e+01, 3.0500e+01, 3.0550e+01, 3.0710e+01, 3.1000e+01,\n       3.1050e+01, 3.1200e+01, 3.1250e+01, 3.1380e+01, 3.1530e+01,\n       3.1540e+01, 3.1690e+01, 3.1750e+01, 3.1850e+01, 3.1880e+01,\n       3.2000e+01, 3.2160e+01, 3.2180e+01, 3.2200e+01, 3.2300e+01,\n       3.2500e+01, 3.2660e+01, 3.2680e+01, 3.2830e+01, 3.3130e+01,\n       3.3600e+01, 3.3750e+01, 3.3800e+01, 3.3950e+01, 3.4130e+01,\n       3.4250e+01, 3.4380e+01, 3.4500e+01, 3.4630e+01, 3.4750e+01,\n       3.5000e+01, 3.5340e+01, 3.5380e+01, 3.5590e+01, 3.5630e+01,\n       3.5640e+01, 3.6000e+01, 3.6100e+01, 3.6300e+01, 3.6400e+01,\n       3.6560e+01, 3.6730e+01, 3.6860e+01, 3.7000e+01, 3.7130e+01,\n       3.7200e+01, 3.7250e+01, 3.7380e+01, 3.7800e+01, 3.8000e+01,\n       3.8020e+01, 3.8150e+01, 3.8250e+01, 3.8350e+01, 3.8500e+01,\n       3.8510e+01, 3.8920e+01, 3.9000e+01, 3.9250e+01, 3.9330e+01,\n       4.0000e+01, 4.0130e+01, 4.0250e+01, 4.0600e+01, 4.0750e+01,\n       4.0950e+01, 4.1130e+01, 4.1250e+01, 4.1270e+01, 4.1420e+01,\n       4.1440e+01, 4.1580e+01, 4.2000e+01, 4.2180e+01, 4.2350e+01,\n       4.2900e+01, 4.3060e+01, 4.3250e+01, 4.3400e+01, 4.3470e+01,\n       4.3550e+01, 4.3750e+01, 4.4060e+01, 4.4500e+01, 4.4840e+01,\n       4.5380e+01, 4.5500e+01, 4.5600e+01, 4.6250e+01, 4.6400e+01,\n       4.6800e+01, 4.6960e+01, 4.7290e+01, 4.7520e+01, 4.7880e+01,\n       4.8000e+01, 4.8300e+01, 4.8420e+01, 4.9240e+01, 4.9400e+01,\n       4.9500e+01, 4.9600e+01, 4.9650e+01, 4.9730e+01, 5.0130e+01,\n       5.0250e+01, 5.0490e+01, 5.0500e+01, 5.0580e+01, 5.0700e+01,\n       5.1130e+01, 5.1200e+01, 5.1450e+01, 5.1750e+01, 5.1980e+01,\n       5.2150e+01, 5.2330e+01, 5.2650e+01, 5.2850e+01, 5.3250e+01,\n       5.3460e+01, 5.3490e+01, 5.4000e+01, 5.4190e+01, 5.4500e+01,\n       5.4600e+01, 5.4900e+01, 5.5250e+01, 5.5480e+01, 5.5860e+01,\n       5.6000e+01, 5.6230e+01, 5.6250e+01, 5.7040e+01, 5.7130e+01,\n       5.7400e+01, 5.7600e+01, 5.7750e+01, 5.8350e+01, 5.8450e+01,\n       5.9000e+01, 5.9150e+01, 5.9400e+01, 5.9880e+01, 6.0000e+01,\n       6.0040e+01, 6.0380e+01, 6.0500e+01, 6.1910e+01, 6.2000e+01,\n       6.2400e+01, 6.2650e+01, 6.3210e+01, 6.3350e+01, 6.3380e+01,\n       6.3700e+01, 6.4050e+01, 6.4350e+01, 6.4380e+01, 6.4800e+01,\n       6.5000e+01, 6.5160e+01, 6.5330e+01, 6.5340e+01, 6.6250e+01,\n       6.7250e+01, 6.7630e+01, 6.7750e+01, 6.8080e+01, 6.8900e+01,\n       6.9160e+01, 6.9250e+01, 6.9300e+01, 6.9710e+01, 7.0200e+01,\n       7.0250e+01, 7.1250e+01, 7.1280e+01, 7.1830e+01, 7.1850e+01,\n       7.2000e+01, 7.2130e+01, 7.2250e+01, 7.2800e+01, 7.2940e+01,\n       7.3250e+01, 7.3450e+01, 7.3600e+01, 7.3690e+01, 7.3850e+01,\n       7.4100e+01, 7.4260e+01, 7.4880e+01, 7.5000e+01, 7.5250e+01,\n       7.5600e+01, 7.6250e+01, 7.7130e+01, 7.7220e+01, 7.8000e+01,\n       7.8280e+01, 7.9250e+01, 7.9630e+01, 8.0000e+01, 8.0440e+01,\n       8.0500e+01, 8.1130e+01, 8.1200e+01, 8.2360e+01, 8.2600e+01,\n       8.3160e+01, 8.3250e+01, 8.5130e+01, 8.5200e+01, 8.9100e+01,\n       8.9380e+01, 8.9960e+01, 9.0090e+01, 9.3600e+01, 9.5040e+01,\n       9.5500e+01, 9.6000e+01, 9.7250e+01, 9.7340e+01, 9.9900e+01,\n       1.0098e+02, 1.0113e+02, 1.0240e+02, 1.0250e+02, 1.0255e+02,\n       1.0300e+02, 1.0692e+02, 1.0725e+02, 1.0800e+02, 1.0822e+02,\n       1.0920e+02, 1.1050e+02, 1.1083e+02, 1.1231e+02, 1.1261e+02,\n       1.1286e+02, 1.1295e+02, 1.1800e+02, 1.1880e+02, 1.2012e+02,\n       1.2050e+02, 1.2288e+02, 1.2474e+02, 1.2675e+02, 1.2775e+02,\n       1.2875e+02, 1.3068e+02, 1.3299e+02, 1.3406e+02, 1.3450e+02,\n       1.3475e+02, 1.3510e+02, 1.3662e+02, 1.3935e+02, 1.4256e+02,\n       1.4850e+02, 1.4937e+02, 1.4950e+02, 1.4975e+02, 1.5444e+02,\n       1.5450e+02, 1.6038e+02, 1.6624e+02, 1.6632e+02, 1.6640e+02,\n       1.6650e+02, 1.6653e+02, 1.6800e+02, 1.7050e+02, 1.7160e+02,\n       1.7226e+02, 1.7820e+02, 1.8414e+02, 1.8655e+02, 1.8671e+02,\n       2.0800e+02, 2.0816e+02, 2.0995e+02, 2.1021e+02, 2.6260e+02,\n       2.6276e+02, 2.8350e+02]),)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\Documents\\masa hackathon\\New folder\\sprint4oridata.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/masa%20hackathon/New%20folder/sprint4oridata.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinear_model\u001b[39;00m \u001b[39mimport\u001b[39;00m SGDClassifier\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/masa%20hackathon/New%20folder/sprint4oridata.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m SGD_model \u001b[39m=\u001b[39m SGDClassifier(max_iter\u001b[39m=\u001b[39m\u001b[39m4000\u001b[39m, penalty\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, eta0\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, alpha\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/masa%20hackathon/New%20folder/sprint4oridata.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m SGD_model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/masa%20hackathon/New%20folder/sprint4oridata.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m SGD_prediction \u001b[39m=\u001b[39m SGD_model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/masa%20hackathon/New%20folder/sprint4oridata.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m accuracy \u001b[39m=\u001b[39m SGD_model\u001b[39m.\u001b[39mscore(y_test, SGD_prediction)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:890\u001b[0m, in \u001b[0;36mBaseSGDClassifier.fit\u001b[1;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    862\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, coef_init\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, intercept_init\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    863\u001b[0m     \u001b[39m\"\"\"Fit linear model with Stochastic Gradient Descent.\u001b[39;00m\n\u001b[0;32m    864\u001b[0m \n\u001b[0;32m    865\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    888\u001b[0m \u001b[39m        Returns an instance of self.\u001b[39;00m\n\u001b[0;32m    889\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 890\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(\n\u001b[0;32m    891\u001b[0m         X,\n\u001b[0;32m    892\u001b[0m         y,\n\u001b[0;32m    893\u001b[0m         alpha\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malpha,\n\u001b[0;32m    894\u001b[0m         C\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m,\n\u001b[0;32m    895\u001b[0m         loss\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss,\n\u001b[0;32m    896\u001b[0m         learning_rate\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearning_rate,\n\u001b[0;32m    897\u001b[0m         coef_init\u001b[39m=\u001b[39;49mcoef_init,\n\u001b[0;32m    898\u001b[0m         intercept_init\u001b[39m=\u001b[39;49mintercept_init,\n\u001b[0;32m    899\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    900\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:686\u001b[0m, in \u001b[0;36mBaseSGDClassifier._fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    683\u001b[0m \u001b[39m# Clear iteration count for multiple call to fit.\u001b[39;00m\n\u001b[0;32m    684\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mt_ \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m\n\u001b[1;32m--> 686\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_partial_fit(\n\u001b[0;32m    687\u001b[0m     X,\n\u001b[0;32m    688\u001b[0m     y,\n\u001b[0;32m    689\u001b[0m     alpha,\n\u001b[0;32m    690\u001b[0m     C,\n\u001b[0;32m    691\u001b[0m     loss,\n\u001b[0;32m    692\u001b[0m     learning_rate,\n\u001b[0;32m    693\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[0;32m    694\u001b[0m     classes,\n\u001b[0;32m    695\u001b[0m     sample_weight,\n\u001b[0;32m    696\u001b[0m     coef_init,\n\u001b[0;32m    697\u001b[0m     intercept_init,\n\u001b[0;32m    698\u001b[0m )\n\u001b[0;32m    700\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    701\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtol \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    702\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtol \u001b[39m>\u001b[39m \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39minf\n\u001b[0;32m    703\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_iter\n\u001b[0;32m    704\u001b[0m ):\n\u001b[0;32m    705\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    706\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMaximum number of iteration reached before \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    707\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mconvergence. Consider increasing max_iter to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    708\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mimprove the fit.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    709\u001b[0m         ConvergenceWarning,\n\u001b[0;32m    710\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:593\u001b[0m, in \u001b[0;36mBaseSGDClassifier._partial_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, classes, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[0;32m    581\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[0;32m    582\u001b[0m     X,\n\u001b[0;32m    583\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    588\u001b[0m     reset\u001b[39m=\u001b[39mfirst_call,\n\u001b[0;32m    589\u001b[0m )\n\u001b[0;32m    591\u001b[0m n_samples, n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape\n\u001b[1;32m--> 593\u001b[0m _check_partial_fit_first_call(\u001b[39mself\u001b[39;49m, classes)\n\u001b[0;32m    595\u001b[0m n_classes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m    597\u001b[0m \u001b[39m# Allocate datastructures from input arguments\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\multiclass.py:368\u001b[0m, in \u001b[0;36m_check_partial_fit_first_call\u001b[1;34m(clf, classes)\u001b[0m\n\u001b[0;32m    361\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    362\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m`classes=\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m` is not the same as on last call \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mto partial_fit, was: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (classes, clf\u001b[39m.\u001b[39mclasses_)\n\u001b[0;32m    364\u001b[0m             )\n\u001b[0;32m    366\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    367\u001b[0m         \u001b[39m# This is the first call to partial_fit\u001b[39;00m\n\u001b[1;32m--> 368\u001b[0m         clf\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m unique_labels(classes)\n\u001b[0;32m    369\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[39m# classes is None and clf.classes_ has already previously been set:\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[39m# nothing to do\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\multiclass.py:103\u001b[0m, in \u001b[0;36munique_labels\u001b[1;34m(*ys)\u001b[0m\n\u001b[0;32m    101\u001b[0m _unique_labels \u001b[39m=\u001b[39m _FN_UNIQUE_LABELS\u001b[39m.\u001b[39mget(label_type, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    102\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _unique_labels:\n\u001b[1;32m--> 103\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnknown label type: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mrepr\u001b[39m(ys))\n\u001b[0;32m    105\u001b[0m ys_labels \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(chain\u001b[39m.\u001b[39mfrom_iterable(_unique_labels(y) \u001b[39mfor\u001b[39;00m y \u001b[39min\u001b[39;00m ys))\n\u001b[0;32m    107\u001b[0m \u001b[39m# Check that we don't mix string type with number type\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: (array([0.0000e+00, 2.0000e-02, 4.0000e-02, 5.0000e-02, 9.0000e-02,\n       1.3000e-01, 1.4000e-01, 1.5000e-01, 1.6000e-01, 1.8000e-01,\n       2.0000e-01, 2.1000e-01, 2.2000e-01, 2.3000e-01, 2.4000e-01,\n       2.5000e-01, 2.6000e-01, 2.7000e-01, 2.8000e-01, 2.9000e-01,\n       3.1000e-01, 3.2000e-01, 3.4000e-01, 3.6000e-01, 3.7000e-01,\n       3.8000e-01, 4.1000e-01, 4.3000e-01, 4.4000e-01, 4.5000e-01,\n       4.7000e-01, 4.9000e-01, 5.0000e-01, 5.1000e-01, 5.4000e-01,\n       5.6000e-01, 5.8000e-01, 5.9000e-01, 6.3000e-01, 6.5000e-01,\n       6.6000e-01, 6.7000e-01, 6.8000e-01, 6.9000e-01, 7.0000e-01,\n       7.1000e-01, 7.4000e-01, 7.5000e-01, 7.7000e-01, 7.9000e-01,\n       8.0000e-01, 8.1000e-01, 8.3000e-01, 8.4000e-01, 8.5000e-01,\n       8.6000e-01, 8.7000e-01, 8.8000e-01, 9.0000e-01, 9.3000e-01,\n       9.4000e-01, 9.5000e-01, 9.6000e-01, 9.7000e-01, 9.8000e-01,\n       9.9000e-01, 1.0000e+00, 1.0100e+00, 1.0200e+00, 1.0300e+00,\n       1.0500e+00, 1.0600e+00, 1.0700e+00, 1.0800e+00, 1.0900e+00,\n       1.1000e+00, 1.1200e+00, 1.1300e+00, 1.1600e+00, 1.1700e+00,\n       1.1800e+00, 1.1900e+00, 1.2000e+00, 1.2100e+00, 1.2200e+00,\n       1.2300e+00, 1.2400e+00, 1.2500e+00, 1.2600e+00, 1.2700e+00,\n       1.2900e+00, 1.3000e+00, 1.3100e+00, 1.3200e+00, 1.3300e+00,\n       1.3400e+00, 1.3700e+00, 1.3900e+00, 1.4200e+00, 1.4300e+00,\n       1.4700e+00, 1.4800e+00, 1.5000e+00, 1.5100e+00, 1.5300e+00,\n       1.5400e+00, 1.5500e+00, 1.5700e+00, 1.5900e+00, 1.6000e+00,\n       1.6100e+00, 1.6300e+00, 1.6500e+00, 1.6600e+00, 1.6800e+00,\n       1.6900e+00, 1.7000e+00, 1.7100e+00, 1.7200e+00, 1.7300e+00,\n       1.7400e+00, 1.7500e+00, 1.7600e+00, 1.8000e+00, 1.8200e+00,\n       1.8400e+00, 1.8600e+00, 1.8800e+00, 1.9000e+00, 1.9400e+00,\n       1.9500e+00, 1.9600e+00, 1.9900e+00, 2.0000e+00, 2.0100e+00,\n       2.0200e+00, 2.0300e+00, 2.0600e+00, 2.1300e+00, 2.1500e+00,\n       2.1600e+00, 2.1900e+00, 2.2000e+00, 2.2100e+00, 2.2200e+00,\n       2.2300e+00, 2.2400e+00, 2.2500e+00, 2.3400e+00, 2.3500e+00,\n       2.3600e+00, 2.3800e+00, 2.4100e+00, 2.4200e+00, 2.4600e+00,\n       2.4700e+00, 2.5100e+00, 2.5200e+00, 2.5600e+00, 2.5700e+00,\n       2.6000e+00, 2.6200e+00, 2.6400e+00, 2.7300e+00, 2.7400e+00,\n       2.7500e+00, 2.7600e+00, 2.8000e+00, 2.8100e+00, 2.8300e+00,\n       2.8700e+00, 2.8800e+00, 2.8900e+00, 2.9100e+00, 2.9200e+00,\n       2.9500e+00, 2.9600e+00, 3.0100e+00, 3.0200e+00, 3.0500e+00,\n       3.0800e+00, 3.0900e+00, 3.1000e+00, 3.1400e+00, 3.1500e+00,\n       3.2100e+00, 3.2300e+00, 3.2500e+00, 3.2800e+00, 3.2900e+00,\n       3.3300e+00, 3.3500e+00, 3.3800e+00, 3.3900e+00, 3.4100e+00,\n       3.4500e+00, 3.4600e+00, 3.5200e+00, 3.5300e+00, 3.5500e+00,\n       3.6000e+00, 3.6100e+00, 3.6200e+00, 3.6600e+00, 3.6800e+00,\n       3.7300e+00, 3.7400e+00, 3.7500e+00, 3.7600e+00, 3.7700e+00,\n       3.8000e+00, 3.8500e+00, 3.8700e+00, 3.9200e+00, 3.9400e+00,\n       3.9500e+00, 4.0000e+00, 4.0200e+00, 4.0300e+00, 4.0400e+00,\n       4.0500e+00, 4.0600e+00, 4.1300e+00, 4.1800e+00, 4.2000e+00,\n       4.2100e+00, 4.2500e+00, 4.2800e+00, 4.3000e+00, 4.3100e+00,\n       4.3800e+00, 4.3900e+00, 4.4000e+00, 4.4300e+00, 4.5000e+00,\n       4.5400e+00, 4.5500e+00, 4.5900e+00, 4.6000e+00, 4.6300e+00,\n       4.6500e+00, 4.6700e+00, 4.7200e+00, 4.7400e+00, 4.8000e+00,\n       4.8800e+00, 4.9100e+00, 4.9200e+00, 4.9300e+00, 4.9400e+00,\n       4.9900e+00, 5.0000e+00, 5.0400e+00, 5.0600e+00, 5.1200e+00,\n       5.1300e+00, 5.1400e+00, 5.2000e+00, 5.2500e+00, 5.2600e+00,\n       5.3400e+00, 5.3800e+00, 5.4800e+00, 5.5000e+00, 5.5300e+00,\n       5.5500e+00, 5.6000e+00, 5.6300e+00, 5.7200e+00, 5.7300e+00,\n       5.7500e+00, 5.7900e+00, 5.8500e+00, 5.8800e+00, 5.9100e+00,\n       5.9300e+00, 5.9400e+00, 5.9500e+00, 5.9800e+00, 6.0000e+00,\n       6.0100e+00, 6.1300e+00, 6.1700e+00, 6.2000e+00, 6.2400e+00,\n       6.2500e+00, 6.2800e+00, 6.3000e+00, 6.3200e+00, 6.3800e+00,\n       6.3900e+00, 6.4200e+00, 6.4700e+00, 6.5000e+00, 6.5100e+00,\n       6.5700e+00, 6.6300e+00, 6.6500e+00, 6.6600e+00, 6.6700e+00,\n       6.7300e+00, 6.7500e+00, 6.8200e+00, 6.8400e+00, 6.8500e+00,\n       6.8800e+00, 6.9400e+00, 6.9600e+00, 6.9900e+00, 7.0000e+00,\n       7.0200e+00, 7.0500e+00, 7.1300e+00, 7.1600e+00, 7.2100e+00,\n       7.2500e+00, 7.3500e+00, 7.3600e+00, 7.3800e+00, 7.4700e+00,\n       7.5000e+00, 7.6400e+00, 7.6900e+00, 7.7000e+00, 7.7600e+00,\n       7.8000e+00, 7.8700e+00, 7.8900e+00, 7.9100e+00, 7.9500e+00,\n       7.9600e+00, 8.0000e+00, 8.0500e+00, 8.0600e+00, 8.1000e+00,\n       8.1300e+00, 8.2100e+00, 8.2200e+00, 8.2500e+00, 8.3600e+00,\n       8.3800e+00, 8.4000e+00, 8.5000e+00, 8.5700e+00, 8.6300e+00,\n       8.6800e+00, 8.7000e+00, 8.7100e+00, 8.7500e+00, 8.7600e+00,\n       8.7700e+00, 8.7800e+00, 8.8100e+00, 8.8500e+00, 8.8800e+00,\n       8.9000e+00, 8.9600e+00, 8.9900e+00, 9.0000e+00, 9.1000e+00,\n       9.1300e+00, 9.1900e+00, 9.2000e+00, 9.2500e+00, 9.2600e+00,\n       9.3000e+00, 9.3800e+00, 9.4500e+00, 9.5700e+00, 9.5900e+00,\n       9.7500e+00, 9.9700e+00, 1.0000e+01, 1.0050e+01, 1.0130e+01,\n       1.0150e+01, 1.0160e+01, 1.0180e+01, 1.0220e+01, 1.0250e+01,\n       1.0320e+01, 1.0330e+01, 1.0380e+01, 1.0500e+01, 1.0630e+01,\n       1.0640e+01, 1.0660e+01, 1.0690e+01, 1.0830e+01, 1.0850e+01,\n       1.0890e+01, 1.1020e+01, 1.1060e+01, 1.1100e+01, 1.1130e+01,\n       1.1200e+01, 1.1210e+01, 1.1250e+01, 1.1340e+01, 1.1380e+01,\n       1.1500e+01, 1.1540e+01, 1.1550e+01, 1.1580e+01, 1.1630e+01,\n       1.1700e+01, 1.1720e+01, 1.1750e+01, 1.1780e+01, 1.1830e+01,\n       1.1860e+01, 1.1880e+01, 1.1900e+01, 1.2000e+01, 1.2070e+01,\n       1.2090e+01, 1.2130e+01, 1.2140e+01, 1.2170e+01, 1.2250e+01,\n       1.2300e+01, 1.2380e+01, 1.2390e+01, 1.2400e+01, 1.2450e+01,\n       1.2500e+01, 1.2540e+01, 1.2560e+01, 1.2600e+01, 1.2630e+01,\n       1.2750e+01, 1.2940e+01, 1.2950e+01, 1.2960e+01, 1.3000e+01,\n       1.3020e+01, 1.3130e+01, 1.3160e+01, 1.3200e+01, 1.3210e+01,\n       1.3250e+01, 1.3310e+01, 1.3380e+01, 1.3420e+01, 1.3490e+01,\n       1.3500e+01, 1.3570e+01, 1.3630e+01, 1.3650e+01, 1.3750e+01,\n       1.3880e+01, 1.3920e+01, 1.3950e+01, 1.4000e+01, 1.4100e+01,\n       1.4130e+01, 1.4180e+01, 1.4250e+01, 1.4380e+01, 1.4440e+01,\n       1.4460e+01, 1.4500e+01, 1.4530e+01, 1.4550e+01, 1.4630e+01,\n       1.4700e+01, 1.4750e+01, 1.4790e+01, 1.4850e+01, 1.4880e+01,\n       1.5000e+01, 1.5190e+01, 1.5280e+01, 1.5380e+01, 1.5400e+01,\n       1.5440e+01, 1.5500e+01, 1.5560e+01, 1.5570e+01, 1.5600e+01,\n       1.5750e+01, 1.5880e+01, 1.5900e+01, 1.5930e+01, 1.5960e+01,\n       1.6000e+01, 1.6050e+01, 1.6090e+01, 1.6160e+01, 1.6250e+01,\n       1.6270e+01, 1.6350e+01, 1.6410e+01, 1.6450e+01, 1.6500e+01,\n       1.6570e+01, 1.6610e+01, 1.6700e+01, 1.6750e+01, 1.6800e+01,\n       1.6900e+01, 1.6950e+01, 1.7130e+01, 1.7150e+01, 1.7230e+01,\n       1.7250e+01, 1.7290e+01, 1.7380e+01, 1.7390e+01, 1.7500e+01,\n       1.7540e+01, 1.7550e+01, 1.7630e+01, 1.7710e+01, 1.7750e+01,\n       1.7820e+01, 1.7850e+01, 1.8000e+01, 1.8040e+01, 1.8130e+01,\n       1.8200e+01, 1.8240e+01, 1.8250e+01, 1.8380e+01, 1.8560e+01,\n       1.8600e+01, 1.8620e+01, 1.8630e+01, 1.8730e+01, 1.8800e+01,\n       1.8850e+01, 1.8900e+01, 1.9000e+01, 1.9010e+01, 1.9050e+01,\n       1.9070e+01, 1.9130e+01, 1.9140e+01, 1.9250e+01, 1.9340e+01,\n       1.9350e+01, 1.9500e+01, 1.9600e+01, 1.9630e+01, 1.9650e+01,\n       1.9950e+01, 1.9990e+01, 2.0000e+01, 2.0030e+01, 2.0060e+01,\n       2.0130e+01, 2.0150e+01, 2.0250e+01, 2.0280e+01, 2.0300e+01,\n       2.0380e+01, 2.0440e+01, 2.0480e+01, 2.0640e+01, 2.0650e+01,\n       2.0690e+01, 2.0700e+01, 2.0750e+01, 2.0800e+01, 2.0820e+01,\n       2.0850e+01, 2.0880e+01, 2.0960e+01, 2.0980e+01, 2.1000e+01,\n       2.1130e+01, 2.1350e+01, 2.1450e+01, 2.1500e+01, 2.1600e+01,\n       2.1630e+01, 2.1700e+01, 2.1750e+01, 2.1850e+01, 2.2000e+01,\n       2.2040e+01, 2.2050e+01, 2.2090e+01, 2.2100e+01, 2.2130e+01,\n       2.2230e+01, 2.2250e+01, 2.2310e+01, 2.2360e+01, 2.2400e+01,\n       2.2470e+01, 2.2730e+01, 2.2750e+01, 2.2910e+01, 2.2960e+01,\n       2.3060e+01, 2.3180e+01, 2.3250e+01, 2.3400e+01, 2.3450e+01,\n       2.3500e+01, 2.3600e+01, 2.3630e+01, 2.3730e+01, 2.3750e+01,\n       2.3760e+01, 2.3810e+01, 2.3970e+01, 2.4000e+01, 2.4150e+01,\n       2.4170e+01, 2.4380e+01, 2.4400e+01, 2.4440e+01, 2.4450e+01,\n       2.4750e+01, 2.4800e+01, 2.4850e+01, 2.4860e+01, 2.5020e+01,\n       2.5080e+01, 2.5130e+01, 2.5200e+01, 2.5250e+01, 2.5480e+01,\n       2.5500e+01, 2.5510e+01, 2.5520e+01, 2.5550e+01, 2.5620e+01,\n       2.5680e+01, 2.5840e+01, 2.5880e+01, 2.6000e+01, 2.6400e+01,\n       2.6500e+01, 2.6550e+01, 2.6590e+01, 2.6600e+01, 2.6630e+01,\n       2.6750e+01, 2.6980e+01, 2.7000e+01, 2.7190e+01, 2.7250e+01,\n       2.7300e+01, 2.7360e+01, 2.7460e+01, 2.7500e+01, 2.7560e+01,\n       2.7750e+01, 2.8000e+01, 2.8130e+01, 2.8250e+01, 2.8280e+01,\n       2.8350e+01, 2.8500e+01, 2.8600e+01, 2.8690e+01, 2.8760e+01,\n       2.8800e+01, 2.8850e+01, 2.8930e+01, 2.8950e+01, 2.9050e+01,\n       2.9130e+01, 2.9380e+01, 2.9440e+01, 2.9500e+01, 2.9570e+01,\n       2.9700e+01, 2.9750e+01, 3.0000e+01, 3.0160e+01, 3.0250e+01,\n       3.0450e+01, 3.0500e+01, 3.0550e+01, 3.0710e+01, 3.1000e+01,\n       3.1050e+01, 3.1200e+01, 3.1250e+01, 3.1380e+01, 3.1530e+01,\n       3.1540e+01, 3.1690e+01, 3.1750e+01, 3.1850e+01, 3.1880e+01,\n       3.2000e+01, 3.2160e+01, 3.2180e+01, 3.2200e+01, 3.2300e+01,\n       3.2500e+01, 3.2660e+01, 3.2680e+01, 3.2830e+01, 3.3130e+01,\n       3.3600e+01, 3.3750e+01, 3.3800e+01, 3.3950e+01, 3.4130e+01,\n       3.4250e+01, 3.4380e+01, 3.4500e+01, 3.4630e+01, 3.4750e+01,\n       3.5000e+01, 3.5340e+01, 3.5380e+01, 3.5590e+01, 3.5630e+01,\n       3.5640e+01, 3.6000e+01, 3.6100e+01, 3.6300e+01, 3.6400e+01,\n       3.6560e+01, 3.6730e+01, 3.6860e+01, 3.7000e+01, 3.7130e+01,\n       3.7200e+01, 3.7250e+01, 3.7380e+01, 3.7800e+01, 3.8000e+01,\n       3.8020e+01, 3.8150e+01, 3.8250e+01, 3.8350e+01, 3.8500e+01,\n       3.8510e+01, 3.8920e+01, 3.9000e+01, 3.9250e+01, 3.9330e+01,\n       4.0000e+01, 4.0130e+01, 4.0250e+01, 4.0600e+01, 4.0750e+01,\n       4.0950e+01, 4.1130e+01, 4.1250e+01, 4.1270e+01, 4.1420e+01,\n       4.1440e+01, 4.1580e+01, 4.2000e+01, 4.2180e+01, 4.2350e+01,\n       4.2900e+01, 4.3060e+01, 4.3250e+01, 4.3400e+01, 4.3470e+01,\n       4.3550e+01, 4.3750e+01, 4.4060e+01, 4.4500e+01, 4.4840e+01,\n       4.5380e+01, 4.5500e+01, 4.5600e+01, 4.6250e+01, 4.6400e+01,\n       4.6800e+01, 4.6960e+01, 4.7290e+01, 4.7520e+01, 4.7880e+01,\n       4.8000e+01, 4.8300e+01, 4.8420e+01, 4.9240e+01, 4.9400e+01,\n       4.9500e+01, 4.9600e+01, 4.9650e+01, 4.9730e+01, 5.0130e+01,\n       5.0250e+01, 5.0490e+01, 5.0500e+01, 5.0580e+01, 5.0700e+01,\n       5.1130e+01, 5.1200e+01, 5.1450e+01, 5.1750e+01, 5.1980e+01,\n       5.2150e+01, 5.2330e+01, 5.2650e+01, 5.2850e+01, 5.3250e+01,\n       5.3460e+01, 5.3490e+01, 5.4000e+01, 5.4190e+01, 5.4500e+01,\n       5.4600e+01, 5.4900e+01, 5.5250e+01, 5.5480e+01, 5.5860e+01,\n       5.6000e+01, 5.6230e+01, 5.6250e+01, 5.7040e+01, 5.7130e+01,\n       5.7400e+01, 5.7600e+01, 5.7750e+01, 5.8350e+01, 5.8450e+01,\n       5.9000e+01, 5.9150e+01, 5.9400e+01, 5.9880e+01, 6.0000e+01,\n       6.0040e+01, 6.0380e+01, 6.0500e+01, 6.1910e+01, 6.2000e+01,\n       6.2400e+01, 6.2650e+01, 6.3210e+01, 6.3350e+01, 6.3380e+01,\n       6.3700e+01, 6.4050e+01, 6.4350e+01, 6.4380e+01, 6.4800e+01,\n       6.5000e+01, 6.5160e+01, 6.5330e+01, 6.5340e+01, 6.6250e+01,\n       6.7250e+01, 6.7630e+01, 6.7750e+01, 6.8080e+01, 6.8900e+01,\n       6.9160e+01, 6.9250e+01, 6.9300e+01, 6.9710e+01, 7.0200e+01,\n       7.0250e+01, 7.1250e+01, 7.1280e+01, 7.1830e+01, 7.1850e+01,\n       7.2000e+01, 7.2130e+01, 7.2250e+01, 7.2800e+01, 7.2940e+01,\n       7.3250e+01, 7.3450e+01, 7.3600e+01, 7.3690e+01, 7.3850e+01,\n       7.4100e+01, 7.4260e+01, 7.4880e+01, 7.5000e+01, 7.5250e+01,\n       7.5600e+01, 7.6250e+01, 7.7130e+01, 7.7220e+01, 7.8000e+01,\n       7.8280e+01, 7.9250e+01, 7.9630e+01, 8.0000e+01, 8.0440e+01,\n       8.0500e+01, 8.1130e+01, 8.1200e+01, 8.2360e+01, 8.2600e+01,\n       8.3160e+01, 8.3250e+01, 8.5130e+01, 8.5200e+01, 8.9100e+01,\n       8.9380e+01, 8.9960e+01, 9.0090e+01, 9.3600e+01, 9.5040e+01,\n       9.5500e+01, 9.6000e+01, 9.7250e+01, 9.7340e+01, 9.9900e+01,\n       1.0098e+02, 1.0113e+02, 1.0240e+02, 1.0250e+02, 1.0255e+02,\n       1.0300e+02, 1.0692e+02, 1.0725e+02, 1.0800e+02, 1.0822e+02,\n       1.0920e+02, 1.1050e+02, 1.1083e+02, 1.1231e+02, 1.1261e+02,\n       1.1286e+02, 1.1295e+02, 1.1800e+02, 1.1880e+02, 1.2012e+02,\n       1.2050e+02, 1.2288e+02, 1.2474e+02, 1.2675e+02, 1.2775e+02,\n       1.2875e+02, 1.3068e+02, 1.3299e+02, 1.3406e+02, 1.3450e+02,\n       1.3475e+02, 1.3510e+02, 1.3662e+02, 1.3935e+02, 1.4256e+02,\n       1.4850e+02, 1.4937e+02, 1.4950e+02, 1.4975e+02, 1.5444e+02,\n       1.5450e+02, 1.6038e+02, 1.6624e+02, 1.6632e+02, 1.6640e+02,\n       1.6650e+02, 1.6653e+02, 1.6800e+02, 1.7050e+02, 1.7160e+02,\n       1.7226e+02, 1.7820e+02, 1.8414e+02, 1.8655e+02, 1.8671e+02,\n       2.0800e+02, 2.0816e+02, 2.0995e+02, 2.1021e+02, 2.6260e+02,\n       2.6276e+02, 2.8350e+02]),)"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "SGD_model = SGDClassifier(max_iter=4000, penalty=None, eta0=0.1, alpha=0.01)\n",
    "SGD_model.fit(X_train, y_train)\n",
    "SGD_prediction = SGD_model.predict(X_test)\n",
    "accuracy = SGD_model.score(y_test, SGD_prediction)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\Documents\\masa hackathon\\New folder\\sprint4oridata.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/masa%20hackathon/New%20folder/sprint4oridata.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m decision_tree \u001b[39m=\u001b[39m DecisionTreeClassifier()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/masa%20hackathon/New%20folder/sprint4oridata.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# fit on the training set\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/masa%20hackathon/New%20folder/sprint4oridata.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m decision_tree\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/masa%20hackathon/New%20folder/sprint4oridata.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# predict on test set\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/masa%20hackathon/New%20folder/sprint4oridata.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m yhat \u001b[39m=\u001b[39m decision_tree\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py:969\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    939\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    940\u001b[0m     \u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    941\u001b[0m \n\u001b[0;32m    942\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    966\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    967\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 969\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    970\u001b[0m         X,\n\u001b[0;32m    971\u001b[0m         y,\n\u001b[0;32m    972\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    973\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m    974\u001b[0m     )\n\u001b[0;32m    975\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py:210\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m    209\u001b[0m \u001b[39mif\u001b[39;00m is_classification:\n\u001b[1;32m--> 210\u001b[0m     check_classification_targets(y)\n\u001b[0;32m    211\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcopy(y)\n\u001b[0;32m    213\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\multiclass.py:200\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    192\u001b[0m y_type \u001b[39m=\u001b[39m type_of_target(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\n\u001b[0;32m    194\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    195\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmultilabel-sequences\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    199\u001b[0m ]:\n\u001b[1;32m--> 200\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnknown label type: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "# fit on the training set\n",
    "decision_tree.fit(X_train, y_train)\n",
    "# predict on test set\n",
    "yhat = decision_tree.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\Documents\\masa hackathon\\New folder\\sprint4oridata.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/masa%20hackathon/New%20folder/sprint4oridata.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m random_forest \u001b[39m=\u001b[39m RandomForestClassifier()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/masa%20hackathon/New%20folder/sprint4oridata.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# fit on the training set\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/masa%20hackathon/New%20folder/sprint4oridata.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m random_forest\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/masa%20hackathon/New%20folder/sprint4oridata.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# predict on test set\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/masa%20hackathon/New%20folder/sprint4oridata.ipynb#X25sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m yhat \u001b[39m=\u001b[39m random_forest\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:371\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    365\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mSum of y is not strictly positive which \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mis necessary for Poisson regression.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    367\u001b[0m         )\n\u001b[0;32m    369\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m--> 371\u001b[0m y, expanded_class_weight \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_y_class_weight(y)\n\u001b[0;32m    373\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(y, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m!=\u001b[39m DOUBLE \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m y\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mcontiguous:\n\u001b[0;32m    374\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mascontiguousarray(y, dtype\u001b[39m=\u001b[39mDOUBLE)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:758\u001b[0m, in \u001b[0;36mForestClassifier._validate_y_class_weight\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    757\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_y_class_weight\u001b[39m(\u001b[39mself\u001b[39m, y):\n\u001b[1;32m--> 758\u001b[0m     check_classification_targets(y)\n\u001b[0;32m    760\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcopy(y)\n\u001b[0;32m    761\u001b[0m     expanded_class_weight \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\multiclass.py:200\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    192\u001b[0m y_type \u001b[39m=\u001b[39m type_of_target(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\n\u001b[0;32m    194\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    195\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmultilabel-sequences\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    199\u001b[0m ]:\n\u001b[1;32m--> 200\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnknown label type: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier()\n",
    "# fit on the training set\n",
    "random_forest.fit(X_train, y_train)\n",
    "# predict on test set\n",
    "yhat = random_forest.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "# cv = cross_val_score(random_forest, X_train, y_train,cv=5)\n",
    "# print('cross validation score of: %.2f' % (cv.mean()*100))\n",
    "score = random_forest.score(X_test, y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100) + ', score of: %.2f' % (score*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afb734500600fd355917ca529030176ea0ca205570884b88f2f6f7d791fd3fbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
